{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb3d2458-3a43-4202-b63f-2a9c727cca26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: image_408.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_408.json\n",
      "Processing: image_1933.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_1933.json\n",
      "Processing: image_420.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_420.json\n",
      "Processing: image_346.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_346.json\n",
      "Processing: image_1099.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_1099.json\n",
      "Processing: image_352.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_352.json\n",
      "Processing: image_434.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_434.json\n",
      "Processing: image_1927.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_1927.json\n",
      "Processing: 1078-receipt.jpg\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/1078-receipt.json\n",
      "Processing: 1085-receipt.jpg\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/1085-receipt.json\n",
      "Processing: image_1714.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_1714.json\n",
      "Processing: image_1072.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_1072.json\n",
      "Processing: image_1066.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_1066.json\n",
      "Processing: image_15.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_15.json\n",
      "Processing: image_1700.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_1700.json\n",
      "Processing: image_1728.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_1728.json\n",
      "Processing: image_385.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_385.json\n",
      "Processing: image_391.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_391.json\n",
      "Processing: image_29.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_29.json\n",
      "Processing: image_178.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_178.json\n",
      "Processing: 1197-receipt.jpg\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/1197-receipt.json\n",
      "Processing: image_144.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_144.json\n",
      "Processing: image_622.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_622.json\n",
      "Processing: image_636.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_636.json\n",
      "Processing: 1008-receipt.jpg\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/1008-receipt.json\n",
      "Processing: image_150.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_150.json\n",
      "Processing: image_1270.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_1270.json\n",
      "Processing: image_805.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_805.json\n",
      "Processing: image_1516.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_1516.json\n",
      "Processing: image_1502.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_1502.json\n",
      "Processing: image_811.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_811.json\n",
      "Processing: image_1264.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_1264.json\n",
      "Processing: image_187.png\n",
      "Saved: /Users/meganshah/Desktop/CapitalGators/processed_json_images/image_187.json\n",
      "Processing: image_839.png\n"
     ]
    },
    {
     "ename": "HttpResponseError",
     "evalue": "(InvalidRequest) Invalid request.\nCode: InvalidRequest\nMessage: Invalid request.\nInner error: {\n    \"code\": \"InvalidContentLength\",\n    \"message\": \"The input image is too large. Refer to documentation for the maximum file size.\"\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 79\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Open the file and analyze\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m receipt_file:\n\u001b[0;32m---> 79\u001b[0m     poller \u001b[38;5;241m=\u001b[39m document_intelligence_client\u001b[38;5;241m.\u001b[39mbegin_analyze_document(\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprebuilt-receipt\u001b[39m\u001b[38;5;124m\"\u001b[39m, receipt_file\n\u001b[1;32m     81\u001b[0m     )\n\u001b[1;32m     82\u001b[0m     receipts \u001b[38;5;241m=\u001b[39m poller\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Process and store extracted receipt information\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/azure/core/tracing/decorator.py:105\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/azure/ai/documentintelligence/_operations/_patch.py:596\u001b[0m, in \u001b[0;36mDocumentIntelligenceClientOperationsMixin.begin_analyze_document\u001b[0;34m(self, model_id, body, pages, locale, string_index_type, features, query_fields, output_content_format, output, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(body, (\u001b[38;5;28mbytes\u001b[39m, io\u001b[38;5;241m.\u001b[39mBytesIO, io\u001b[38;5;241m.\u001b[39mBufferedReader)):\n\u001b[1;32m    595\u001b[0m         content_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/octet-stream\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 596\u001b[0m     raw_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_analyze_document_initial(\n\u001b[1;32m    597\u001b[0m         model_id\u001b[38;5;241m=\u001b[39mmodel_id,\n\u001b[1;32m    598\u001b[0m         body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    599\u001b[0m         pages\u001b[38;5;241m=\u001b[39mpages,\n\u001b[1;32m    600\u001b[0m         locale\u001b[38;5;241m=\u001b[39mlocale,\n\u001b[1;32m    601\u001b[0m         string_index_type\u001b[38;5;241m=\u001b[39mstring_index_type,\n\u001b[1;32m    602\u001b[0m         features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[1;32m    603\u001b[0m         query_fields\u001b[38;5;241m=\u001b[39mquery_fields,\n\u001b[1;32m    604\u001b[0m         output_content_format\u001b[38;5;241m=\u001b[39moutput_content_format,\n\u001b[1;32m    605\u001b[0m         output\u001b[38;5;241m=\u001b[39moutput,\n\u001b[1;32m    606\u001b[0m         content_type\u001b[38;5;241m=\u001b[39mcontent_type,\n\u001b[1;32m    607\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x, y, z: x,\n\u001b[1;32m    608\u001b[0m         headers\u001b[38;5;241m=\u001b[39m_headers,\n\u001b[1;32m    609\u001b[0m         params\u001b[38;5;241m=\u001b[39m_params,\n\u001b[1;32m    610\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    611\u001b[0m     )\n\u001b[1;32m    612\u001b[0m     raw_result\u001b[38;5;241m.\u001b[39mhttp_response\u001b[38;5;241m.\u001b[39mread()  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    613\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/azure/ai/documentintelligence/_operations/_operations.py:819\u001b[0m, in \u001b[0;36mDocumentIntelligenceClientOperationsMixin._analyze_document_initial\u001b[0;34m(self, model_id, body, pages, locale, string_index_type, features, query_fields, output_content_format, output, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m     map_error(status_code\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m=\u001b[39mresponse, error_map\u001b[38;5;241m=\u001b[39merror_map)\n\u001b[1;32m    818\u001b[0m     error \u001b[38;5;241m=\u001b[39m _failsafe_deserialize(_models\u001b[38;5;241m.\u001b[39mDocumentIntelligenceErrorResponse, response\u001b[38;5;241m.\u001b[39mjson())\n\u001b[0;32m--> 819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39mresponse, model\u001b[38;5;241m=\u001b[39merror)\n\u001b[1;32m    821\u001b[0m response_headers \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    822\u001b[0m response_headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetry-After\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetry-After\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mHttpResponseError\u001b[0m: (InvalidRequest) Invalid request.\nCode: InvalidRequest\nMessage: Invalid request.\nInner error: {\n    \"code\": \"InvalidContentLength\",\n    \"message\": \"The input image is too large. Refer to documentation for the maximum file size.\"\n}"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Set up your Azure AI Document Intelligence credentials\n",
    "endpoint = \"https://receiptprocess.cognitiveservices.azure.com/\"  # Replace with your endpoint\n",
    "key = \"CSDnP6rbFAgzLtbUpfkYzItnfxm1Z9KHdT1DWr7H7WypMFLoRwQOJQQJ99BBACYeBjFXJ3w3AAALACOGWgTA\"  # Replace with your key\n",
    "\n",
    "# Directory containing receipt images\n",
    "input_dir = \"/Users/meganshah/Desktop/CapitalGators/big_receipt_dataset\"\n",
    "# Directory to store JSON output\n",
    "output_dir = \"/Users/meganshah/Desktop/CapitalGators/processed_json_images\"\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize the client\n",
    "document_intelligence_client = DocumentIntelligenceClient(\n",
    "    endpoint=endpoint, credential=AzureKeyCredential(key)\n",
    ")\n",
    "\n",
    "# Function to serialize date objects\n",
    "def serialize_date(date_obj):\n",
    "    if date_obj:\n",
    "        return date_obj.strftime(\"%Y-%m-%d\")\n",
    "    return None\n",
    "\n",
    "# Function to safely get a value from a field\n",
    "def get_field_value(field, field_type=\"string\"):\n",
    "    if field:\n",
    "        if field_type == \"string\":\n",
    "            return field.value_string if field.value_string else None\n",
    "        elif field_type == \"date\":\n",
    "            return serialize_date(field.value_date) if field.value_date else None\n",
    "        elif field_type == \"currency\":\n",
    "            return field.value_currency.amount if field.value_currency else None\n",
    "        elif field_type == \"number\":\n",
    "            return field.value_number if field.value_number else None\n",
    "    return None\n",
    "\n",
    "# Function to resize the image if it's too large\n",
    "def resize_image(image_path, max_size=(800, 800), max_quality=85):\n",
    "    with Image.open(image_path) as img:\n",
    "        print(f\"Original image size: {os.path.getsize(image_path) / (1024 * 1024):.2f} MB\")\n",
    "        \n",
    "        # Resize image to fit within max_size\n",
    "        img.thumbnail(max_size)\n",
    "        \n",
    "        # Save resized image as JPEG with reduced quality\n",
    "        resized_image_path = os.path.splitext(image_path)[0] + \"_resized.jpg\"\n",
    "        img.save(resized_image_path, \"JPEG\", quality=max_quality)  # Adjust quality to reduce file size\n",
    "        \n",
    "        print(f\"Resized image saved as: {resized_image_path}\")\n",
    "        print(f\"Resized image size: {os.path.getsize(resized_image_path) / (1024 * 1024):.2f} MB\")\n",
    "        \n",
    "    return resized_image_path\n",
    "\n",
    "# Loop through all files in the input directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    file_path = os.path.join(input_dir, filename)\n",
    "    \n",
    "    # Check if it's an image file (you can add more extensions if needed)\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.pdf')):\n",
    "        print(f\"Processing: {filename}\")\n",
    "\n",
    "        # Check the file size (e.g., 50 MB limit)\n",
    "        file_size = os.path.getsize(file_path)  # Size in bytes\n",
    "        if file_size > 50 * 1024 * 1024:  # 50 MB in bytes\n",
    "            print(f\"File is too large ({file_size / (1024 * 1024):.2f} MB). Resizing...\")\n",
    "            resized_image_path = resize_image(file_path)  # Resize the image\n",
    "            file_path = resized_image_path  # Use the resized image for processing\n",
    "            print(f\"Resized image saved as: {resized_image_path}\")\n",
    "\n",
    "        # Open the file and analyze\n",
    "        with open(file_path, \"rb\") as receipt_file:\n",
    "            poller = document_intelligence_client.begin_analyze_document(\n",
    "                \"prebuilt-receipt\", receipt_file\n",
    "            )\n",
    "            receipts = poller.result()\n",
    "\n",
    "        # Process and store extracted receipt information\n",
    "        receipt_data = []\n",
    "        for idx, receipt in enumerate(receipts.documents):\n",
    "            receipt_info = {\n",
    "                \"receipt_number\": idx + 1,\n",
    "                \"receipt_type\": receipt.doc_type,\n",
    "                \"merchant_name\": get_field_value(receipt.fields.get(\"MerchantName\")),\n",
    "                \"transaction_date\": get_field_value(receipt.fields.get(\"TransactionDate\"), \"date\"),\n",
    "                \"items\": []\n",
    "            }\n",
    "\n",
    "            if receipt.fields.get(\"Items\"):\n",
    "                for item in receipt.fields.get(\"Items\").value_array:\n",
    "                    receipt_info[\"items\"].append({\n",
    "                        \"description\": get_field_value(item.value_object.get(\"Description\")),\n",
    "                        \"quantity\": get_field_value(item.value_object.get(\"Quantity\"), \"number\"),\n",
    "                        \"price\": get_field_value(item.value_object.get(\"Price\"), \"currency\"),\n",
    "                        \"total_price\": get_field_value(item.value_object.get(\"TotalPrice\"), \"currency\")\n",
    "                    })\n",
    "\n",
    "            receipt_info[\"subtotal\"] = get_field_value(receipt.fields.get(\"Subtotal\"), \"currency\")\n",
    "            receipt_info[\"tax\"] = get_field_value(receipt.fields.get(\"TotalTax\"), \"currency\")\n",
    "            receipt_info[\"tip\"] = get_field_value(receipt.fields.get(\"Tip\"), \"currency\")\n",
    "            receipt_info[\"total\"] = get_field_value(receipt.fields.get(\"Total\"), \"currency\")\n",
    "            \n",
    "            receipt_data.append(receipt_info)\n",
    "\n",
    "        # Convert to JSON format\n",
    "        receipt_json = json.dumps(receipt_data, indent=4)\n",
    "\n",
    "        # Write JSON output to the output directory\n",
    "        output_path = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}.json\")\n",
    "        with open(output_path, \"w\") as json_file:\n",
    "            json_file.write(receipt_json)\n",
    "        \n",
    "        print(f\"Saved: {output_path}\")\n",
    "\n",
    "print(\"Processing complete! ðŸŽ‰\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a4240e-960f-4603-8c44-d077997f06b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
