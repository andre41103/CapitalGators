{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dabd7c43-96e1-4214-afb6-d91fdfd831a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“š Training on 157 users with features: ['total', 'date_range', 'recurring_total', 'daily_nonrec']\n",
      "ğŸ§ª Testing on 40 users\n",
      "\n",
      "âœ… Training Complete.\n",
      "ğŸ“ˆ Training MAE: 6203.29\n",
      "ğŸ“ˆ Training Accuracy: 94.76%\n",
      "\n",
      "ğŸ¯ Final Evaluation on Test Set\n",
      "ğŸ“Š Test MAE: 5224.32\n",
      "ğŸ“Š Test Accuracy: 92.30%\n",
      "\n",
      "ğŸ” Per-user predictions:\n",
      "User   1: Predicted =  28896.09 | Actual =  24093.38 | Error = 4802.72\n",
      "User   2: Predicted =   2064.29 | Actual =   2471.41 | Error =  407.11\n",
      "User   3: Predicted =   5199.35 | Actual =   4197.03 | Error = 1002.31\n",
      "User   4: Predicted =  75346.92 | Actual =  76480.98 | Error = 1134.06\n",
      "User   5: Predicted =   3366.18 | Actual =   3488.76 | Error =  122.58\n",
      "User   6: Predicted = 115316.91 | Actual = 122205.75 | Error = 6888.84\n",
      "User   7: Predicted =    487.44 | Actual =    346.80 | Error =  140.64\n",
      "User   8: Predicted = 548612.70 | Actual = 527238.08 | Error = 21374.62\n",
      "User   9: Predicted =  76794.45 | Actual =  75955.38 | Error =  839.07\n",
      "User  10: Predicted =  52544.57 | Actual =  58187.69 | Error = 5643.12\n",
      "User  11: Predicted =   6445.85 | Actual =   5440.56 | Error = 1005.29\n",
      "User  12: Predicted =  61981.73 | Actual =  64962.10 | Error = 2980.37\n",
      "User  13: Predicted = 456509.44 | Actual = 501278.44 | Error = 44769.00\n",
      "User  14: Predicted =    549.41 | Actual =    466.62 | Error =   82.78\n",
      "User  15: Predicted =  99976.55 | Actual =  96014.64 | Error = 3961.91\n",
      "User  16: Predicted =  44092.88 | Actual =  43032.54 | Error = 1060.34\n",
      "User  17: Predicted =   2020.37 | Actual =   2109.15 | Error =   88.78\n",
      "User  18: Predicted = 100239.00 | Actual =  95069.39 | Error = 5169.61\n",
      "User  19: Predicted =  13292.63 | Actual =  12144.83 | Error = 1147.80\n",
      "User  20: Predicted =   1862.77 | Actual =   1943.10 | Error =   80.33\n",
      "User  21: Predicted =   1046.84 | Actual =    899.71 | Error =  147.13\n",
      "User  22: Predicted =  33887.47 | Actual =  30586.14 | Error = 3301.33\n",
      "User  23: Predicted =   9301.31 | Actual =  10744.06 | Error = 1442.75\n",
      "User  24: Predicted =  16433.24 | Actual =  14039.20 | Error = 2394.03\n",
      "User  25: Predicted =  32764.62 | Actual =  21134.87 | Error = 11629.75\n",
      "User  26: Predicted =   1091.61 | Actual =    838.93 | Error =  252.68\n",
      "User  27: Predicted =   5590.88 | Actual =   4819.54 | Error =  771.34\n",
      "User  28: Predicted =    799.52 | Actual =    626.07 | Error =  173.45\n",
      "User  29: Predicted =  34325.53 | Actual =  28000.28 | Error = 6325.25\n",
      "User  30: Predicted =   6789.85 | Actual =   6823.68 | Error =   33.83\n",
      "User  31: Predicted =   8286.20 | Actual =   8161.43 | Error =  124.77\n",
      "User  32: Predicted = 189885.91 | Actual = 239849.93 | Error = 49964.02\n",
      "User  33: Predicted =   1570.18 | Actual =   1784.53 | Error =  214.35\n",
      "User  34: Predicted = 430963.23 | Actual = 449914.10 | Error = 18950.87\n",
      "User  35: Predicted =    942.65 | Actual =   1073.07 | Error =  130.42\n",
      "User  36: Predicted =   7009.60 | Actual =   6666.36 | Error =  343.24\n",
      "User  37: Predicted = 141702.40 | Actual = 134871.71 | Error = 6830.69\n",
      "User  38: Predicted =   8074.60 | Actual =   9823.90 | Error = 1749.30\n",
      "User  39: Predicted =   2757.05 | Actual =   2685.41 | Error =   71.64\n",
      "User  40: Predicted =  22755.36 | Actual =  24176.15 | Error = 1420.79\n",
      "\n",
      "ğŸ“‰ Baseline MAE: 0.00, Accuracy: 100.00%\n",
      "ğŸ” Linear Regression MAE: 0.00, Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# === Load features and targets from user_total.json ===\n",
    "def load_user_totals(root_dir):\n",
    "    data = []\n",
    "    targets = []\n",
    "    for user in os.listdir(root_dir):\n",
    "        user_path = os.path.join(root_dir, user)\n",
    "        total_path = os.path.join(user_path, 'user_total.json')\n",
    "\n",
    "        if os.path.isfile(total_path):\n",
    "            try:\n",
    "                with open(total_path, 'r') as f:\n",
    "                    info = json.load(f)\n",
    "\n",
    "                total = info.get('total')\n",
    "                date_range = info.get('date_range')\n",
    "                recurring_total = info.get('recurring_total', 0)\n",
    "\n",
    "                if None not in (total, date_range) and date_range > 0:\n",
    "                    # Clamp to 30-day logic\n",
    "                    date_range = max(1, min(date_range, 30))\n",
    "\n",
    "                    daily_nonrec = (total - recurring_total) / date_range\n",
    "                    projected = daily_nonrec * 30 + recurring_total\n",
    "\n",
    "                    features = {\n",
    "                        'total': total,\n",
    "                        'date_range': date_range,\n",
    "                        'recurring_total': recurring_total,\n",
    "                        'daily_nonrec': daily_nonrec,\n",
    "                        'projected_baseline': projected\n",
    "                    }\n",
    "\n",
    "                    data.append(features)\n",
    "                    targets.append(projected)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {user} due to error: {e}\")\n",
    "\n",
    "    return pd.DataFrame(data), np.array(targets)\n",
    "\n",
    "\n",
    "\n",
    "# === Load datasets ===\n",
    "X_train_full, y_train = load_user_totals('train')\n",
    "X_test_full, y_test = load_user_totals('test')\n",
    "\n",
    "# Drop leakage feature before training\n",
    "X_train = X_train_full.drop(columns=['projected_baseline'])\n",
    "X_test = X_test_full.drop(columns=['projected_baseline'])\n",
    "\n",
    "print(f\"\\nğŸ“š Training on {len(X_train)} users with features: {list(X_train.columns)}\")\n",
    "print(f\"ğŸ§ª Testing on {len(X_test)} users\\n\")\n",
    "\n",
    "# === Phase 1: Train the model ===\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "train_preds = model.predict(X_train)\n",
    "\n",
    "# Training metrics\n",
    "train_mae = mean_absolute_error(y_train, train_preds)\n",
    "train_acc = 1 - (train_mae / np.mean(y_train))\n",
    "\n",
    "print(\"âœ… Training Complete.\")\n",
    "print(f\"ğŸ“ˆ Training MAE: {train_mae:.2f}\")\n",
    "print(f\"ğŸ“ˆ Training Accuracy: {train_acc * 100:.2f}%\")\n",
    "\n",
    "# === Phase 2: Test the model ===\n",
    "test_preds = model.predict(X_test)\n",
    "\n",
    "# Test metrics\n",
    "test_mae = mean_absolute_error(y_test, test_preds)\n",
    "test_acc = 1 - (test_mae / np.mean(y_test))\n",
    "\n",
    "print(\"\\nğŸ¯ Final Evaluation on Test Set\")\n",
    "print(f\"ğŸ“Š Test MAE: {test_mae:.2f}\")\n",
    "print(f\"ğŸ“Š Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "\n",
    "# === Optional: Print per-user prediction breakdown ===\n",
    "print(\"\\nğŸ” Per-user predictions:\")\n",
    "for i in range(len(y_test)):\n",
    "    print(f\"User {i+1:3}: Predicted = {test_preds[i]:9.2f} | Actual = {y_test[i]:9.2f} | Error = {abs(test_preds[i] - y_test[i]):7.2f}\")\n",
    "\n",
    "# === Optional: Baseline model ===\n",
    "baseline_preds = X_test_full['projected_baseline']\n",
    "baseline_mae = mean_absolute_error(y_test, baseline_preds)\n",
    "baseline_acc = 1 - (baseline_mae / np.mean(y_test))\n",
    "print(f\"\\nğŸ“‰ Baseline MAE: {baseline_mae:.2f}, Accuracy: {baseline_acc * 100:.2f}%\")\n",
    "\n",
    "# === Optional: Linear Regression model ===\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_preds = lr.predict(X_test)\n",
    "lr_mae = mean_absolute_error(y_test, lr_preds)\n",
    "lr_acc = 1 - (lr_mae / np.mean(y_test))\n",
    "print(f\"ğŸ” Linear Regression MAE: {lr_mae:.2f}, Accuracy: {lr_acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9852c2ce-2493-4daf-a728-9ce8e366eb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Model and feature list saved using pickle.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save trained model\n",
    "with open('random_forest_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Save feature names (so future predictions use same order)\n",
    "with open('model_features.pkl', 'wb') as f:\n",
    "    pickle.dump(list(X_train.columns), f)\n",
    "\n",
    "print(\"ğŸ“¦ Model and feature list saved using pickle.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01a56c6-2660-4cdb-8f27-f94525c55b26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
